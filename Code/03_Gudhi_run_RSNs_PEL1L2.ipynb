{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8101f07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gudhi as gd\n",
    "import gudhi.representations\n",
    "import os, re, time\n",
    "import numpy as np\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a39f9",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8ff33f6-41b7-4050-8eda-9a117505cfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 [29, 35, 26, 22, 12, 30, 46] ['Visual', 'Somato Motor', 'Dorsal Attention', 'Salient Ventral Attention', 'Limbic', 'Control', 'Default']\n"
     ]
    }
   ],
   "source": [
    "RSNs_details = pd.read_csv('../Data/SchaeferAtlas_Regions_details.csv')\n",
    "RSNs7 = RSNs_details['RSN'].unique().tolist()\n",
    "\n",
    "## Stores the node_ID for each RSNs\n",
    "result_dict = {key: RSNs_details.loc[RSNs_details['RSN'] == key, 'Node_number'].tolist() for key in RSNs7}\n",
    "\n",
    "print(len(result_dict),[ len(x) for x in result_dict.values()],RSNs7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ab758c-1dd2-4adf-8de6-2c23937435c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = 'MPI_LEMON'\n",
    "dataset = 'ABIDE'\n",
    "path_file = f'../Data/{dataset}/FCM_DistMat/'\n",
    "\n",
    "files_list = os.listdir(path_file)\n",
    "print(len(files_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6abdac45-a697-4fdd-b71a-11d565c0ae7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASD 395 \t Healthy 425 \tTotal: 820\n",
      "50601 50551\n"
     ]
    }
   ],
   "source": [
    "if dataset == 'MPI_LEMON':\n",
    "    Detailsfile = pd.read_csv('../Data/MPI_LEMON/MPILemon_Subject_details.csv')\n",
    "    Young = list(map(str, list(Detailsfile.loc[Detailsfile['Cohort'] == 'Young','Subject'])))\n",
    "    Elder = list(map(str, list(Detailsfile.loc[Detailsfile['Cohort'] == 'Elderly','Subject'])))\n",
    "    All_subs = Young + Elder\n",
    "    Group1, Group2 = 'Young', 'Elderly'\n",
    "    GR1, GR2 = Young, Elder\n",
    "\n",
    "elif dataset == 'ABIDE':\n",
    "    Detailsfile = pd.read_csv('../Data/ABIDE/ABIDE_Subject_details.csv')\n",
    "    ASD = list(map(str, list(Detailsfile.loc[Detailsfile['Cohort'] == 'ASD','Subject identifier'])))\n",
    "    Healthy = list(map(str, list(Detailsfile.loc[Detailsfile['Cohort'] == 'HC','Subject identifier'])))\n",
    "    All_subs = ASD + Healthy\n",
    "    Group1, Group2 = 'ASD', 'Healthy'\n",
    "    GR1, GR2 = ASD, Healthy\n",
    "\n",
    "print(Group1, len(GR1), '\\t', Group2, len(GR2), '\\tTotal:', len(All_subs))\n",
    "print(GR1[0], GR2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2451c2",
   "metadata": {},
   "source": [
    "# Persistent Homology Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ce4aa04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114]\n",
      "Done for  Visual for 820 subjects.  65.89000988006592 -------------------------------------------------- \n",
      "\n",
      "35 [14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133]\n",
      "Done for  Somato Motor for 820 subjects.  85.0373547077179 -------------------------------------------------- \n",
      "\n",
      "26 [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146]\n",
      "Done for  Dorsal Attention for 820 subjects.  50.07950568199158 -------------------------------------------------- \n",
      "\n",
      "22 [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157]\n",
      "Done for  Salient Ventral Attention for 820 subjects.  42.59439420700073 -------------------------------------------------- \n",
      "\n",
      "12 [54, 55, 56, 57, 58, 59, 158, 159, 160, 161, 162, 163]\n",
      "Done for  Limbic for 820 subjects.  30.37323021888733 -------------------------------------------------- \n",
      "\n",
      "30 [60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180]\n",
      "Done for  Control for 820 subjects.  59.66292214393616 -------------------------------------------------- \n",
      "\n",
      "46 [73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199]\n",
      "Done for  Default for 820 subjects.  206.44323420524597 -------------------------------------------------- \n",
      "\n",
      "DONE ABIDE 540.0806510448456\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "for RSN in RSNs7:\n",
    "    t1 = time.time()\n",
    "    dgms_list = list()\n",
    "    barcode0_list = list()\n",
    "    barcode1_list = list()\n",
    "    barcode2_list = list()\n",
    "    indices = result_dict[RSN]\n",
    "    print(len(indices), indices)\n",
    "    for i in range(len(files_list)):\n",
    "        t2 = time.time()\n",
    "        SubID = files_list[i].split('.')[0].split('_')[-1]\n",
    "        DisMat = pd.read_csv(path_file + files_list[i], header = None, sep = ',').values\n",
    "        thres = np.sqrt(2)\n",
    "        # Extract specific rows and columns\n",
    "        DisMat_rsn = DisMat[np.ix_(indices, indices)]\n",
    "        DisMat_rsn[DisMat_rsn > np.sqrt(2)] = thres\n",
    "        # print(DisMat_rsn.shape)\n",
    "        skeleton = gd.RipsComplex(distance_matrix = DisMat_rsn, max_edge_length=thres, sparse=None)\n",
    "        Rips_simplex_tree = skeleton.create_simplex_tree(max_dimension=3)\n",
    "        BarCodes_Rips = Rips_simplex_tree.persistence()\n",
    "        dgms_list.append({SubID: np.array([list(bars[1]) for bars in BarCodes_Rips])})\n",
    "        barcode0_list.append({SubID: Rips_simplex_tree.persistence_intervals_in_dimension(0)})\n",
    "        barcode1_list.append({SubID: Rips_simplex_tree.persistence_intervals_in_dimension(1)})\n",
    "        barcode2_list.append({SubID: Rips_simplex_tree.persistence_intervals_in_dimension(2)})\n",
    "        # break\n",
    "\n",
    "\n",
    "    # Stores the barcodes separately for each RSNs\n",
    "    rsn = RSN.replace(' ','')\n",
    "    outpath = f'../OutputFiles/PosCorr/{dataset}/Output_RSNs/{rsn}/'\n",
    "    os.makedirs(outpath, exist_ok=True)\n",
    "    with open(outpath +f'{rsn}_dgms_list.pkl','wb') as f:\n",
    "        pkl.dump(dgms_list, f)    \n",
    "    with open(outpath +f'{rsn}_barcode0_list.pkl','wb') as f:\n",
    "        pkl.dump(barcode0_list, f)\n",
    "    with open(outpath +f'{rsn}_barcode1_list.pkl','wb') as f:\n",
    "        pkl.dump(barcode1_list, f)\n",
    "    with open(outpath +f'{rsn}_barcode2_list.pkl','wb') as f:\n",
    "        pkl.dump(barcode2_list, f)\n",
    "    print('Done for ',RSN,f'for {i+1} subjects. ',time.time() - t1, '-'*50, '\\n')\n",
    "\n",
    "print('DONE', dataset, time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ec5a61a-177f-43c6-ac17-1bedf9aa16f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened input files for    Visual\n",
      "820 820 820 820\n",
      "Done for   Visual\n",
      "Opened input files for    Somato Motor\n",
      "820 820 820 820\n",
      "Done for   Somato Motor\n",
      "Opened input files for    Dorsal Attention\n",
      "820 820 820 820\n",
      "Done for   Dorsal Attention\n",
      "Opened input files for    Salient Ventral Attention\n",
      "820 820 820 820\n",
      "Done for   Salient Ventral Attention\n",
      "Opened input files for    Limbic\n",
      "820 820 820 820\n",
      "Done for   Limbic\n",
      "Opened input files for    Control\n",
      "820 820 820 820\n",
      "Done for   Control\n",
      "Opened input files for    Default\n",
      "820 820 820 820\n",
      "Done for   Default\n",
      "DONE\n",
      "ASD 395 \t Healthy 425\n"
     ]
    }
   ],
   "source": [
    "for RSN in RSNs7:\n",
    "    rsn = RSN.replace(' ','')\n",
    "    outpath = f'../OutputFiles/PosCorr/{dataset}/Output_RSNs/{rsn}/'\n",
    "    with open(outpath +f'{rsn}_dgms_list.pkl','rb') as f:\n",
    "        dgms_list = pkl.load(f)\n",
    "    with open(outpath +f'{rsn}_barcode0_list.pkl','rb') as f:\n",
    "        barcode0_list = pkl.load(f)\n",
    "    with open(outpath +f'{rsn}_barcode1_list.pkl','rb') as f:\n",
    "        barcode1_list = pkl.load(f)\n",
    "    with open(outpath +f'{rsn}_barcode2_list.pkl','rb') as f:\n",
    "        barcode2_list = pkl.load(f)\n",
    "\n",
    "    print('Opened input files for   ', RSN)\n",
    "    print(len(dgms_list), len(barcode0_list), len(barcode1_list), len(barcode2_list))\n",
    "    Group1_dgms_list, Group2_dgms_list = list(), list()\n",
    "    Group1_barcode0_list, Group2_barcode0_list = list(), list()\n",
    "    Group1_barcode1_list, Group2_barcode1_list = list(), list()\n",
    "    Group1_barcode2_list, Group2_barcode2_list = list(), list()\n",
    "    G1_ID_list, G2_ID_list = list(), list()\n",
    "    \n",
    "    for i in range(len(files_list)):\n",
    "        t1 = time.time()\n",
    "        SubID = files_list[i].split('.')[0].split('_')[-1]\n",
    "        # print(i,SubID,type(SubID))\n",
    "        if SubID in GR1:\n",
    "            Group1_dgms_list.append(dgms_list[i][SubID])\n",
    "            Group1_barcode0_list.append(barcode0_list[i][SubID])\n",
    "            Group1_barcode1_list.append(barcode1_list[i][SubID])\n",
    "            Group1_barcode2_list.append(barcode2_list[i][SubID])\n",
    "            G1_ID_list.append(SubID)\n",
    "            #print(f'Done for {Group1} ',i,SubID,time.time() - t1)\n",
    "        elif SubID in GR2:\n",
    "            Group2_dgms_list.append(dgms_list[i][SubID])\n",
    "            Group2_barcode0_list.append(barcode0_list[i][SubID])\n",
    "            Group2_barcode1_list.append(barcode1_list[i][SubID])\n",
    "            Group2_barcode2_list.append(barcode2_list[i][SubID])\n",
    "            G2_ID_list.append(SubID)\n",
    "    \n",
    "    with open(outpath +f'{rsn}_{Group1}_dgms_list.pkl','wb') as f:\n",
    "        pkl.dump(Group1_dgms_list, f)\n",
    "    with open(outpath +f'{rsn}_{Group1}_barcode0_list.pkl','wb') as f:\n",
    "        pkl.dump(Group1_barcode0_list, f)\n",
    "    with open(outpath +f'{rsn}_{Group1}_barcode1_list.pkl','wb') as f:\n",
    "        pkl.dump(Group1_barcode1_list, f)\n",
    "    with open(outpath +f'{rsn}_{Group1}_barcode2_list.pkl','wb') as f:\n",
    "        pkl.dump(Group1_barcode2_list, f)\n",
    "    \n",
    "    with open(outpath +f'{rsn}_{Group2}_dgms_list.pkl','wb') as f:\n",
    "        pkl.dump(Group2_dgms_list, f)\n",
    "    with open(outpath +f'{rsn}_{Group2}_barcode0_list.pkl','wb') as f:\n",
    "        pkl.dump(Group2_barcode0_list, f)\n",
    "    with open(outpath +f'{rsn}_{Group2}_barcode1_list.pkl','wb') as f:\n",
    "        pkl.dump(Group2_barcode1_list, f)\n",
    "    with open(outpath +f'{rsn}_{Group2}_barcode2_list.pkl','wb') as f:\n",
    "        pkl.dump(Group2_barcode2_list, f)\n",
    "    print('Done for  ', RSN)\n",
    "    # break\n",
    "print('DONE')\n",
    "print(Group1, len(Group1_barcode0_list), '\\t', Group2, len(Group2_barcode0_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5a440f",
   "metadata": {},
   "source": [
    "## Persistence Landscape and Persistent Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250e76c4-a0a8-4ece-bd5b-12fe5527799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_infinity_by_thres(barcode):\n",
    "    for bars in barcode:\n",
    "        for bar in bars:\n",
    "            if bar[1] == np.inf:\n",
    "                bar[1]=np.sqrt(2)\n",
    "    return barcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ad278d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done  ASD \t (395, 4)\n",
      "Done  Healthy \t (425, 4)\n",
      "Done for Visual --------------------------------------------------------------------------------\n",
      "Done  ASD \t (395, 4)\n",
      "Done  Healthy \t (425, 4)\n",
      "Done for SomatoMotor --------------------------------------------------------------------------------\n",
      "Done  ASD \t (395, 4)\n",
      "Done  Healthy \t (425, 4)\n",
      "Done for DorsalAttention --------------------------------------------------------------------------------\n",
      "Done  ASD \t (395, 4)\n",
      "Done  Healthy \t (425, 4)\n",
      "Done for SalientVentralAttention --------------------------------------------------------------------------------\n",
      "Done  ASD \t (395, 4)\n",
      "Done  Healthy \t (425, 4)\n",
      "Done for Limbic --------------------------------------------------------------------------------\n",
      "Done  ASD \t (395, 4)\n",
      "Done  Healthy \t (425, 4)\n",
      "Done for Control --------------------------------------------------------------------------------\n",
      "Done  ASD \t (395, 4)\n",
      "Done  Healthy \t (425, 4)\n",
      "Done for Default --------------------------------------------------------------------------------\n",
      "Done 1.7722387313842773\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "for RSN in RSNs7:\n",
    "    rsn = RSN.replace(' ','')\n",
    "    outpath = f'../OutputFiles/PosCorr/{dataset}/Output_RSNs/{rsn}/'\n",
    "    outpath = f'../Outputs_RSN/Positive_weight/{dataset}/Barcodes_GlobalMeasures/{rsn}/'\n",
    "    for grp in [Group1, Group2]:\n",
    "        with open(outpath +f'{rsn}_{grp}_dgms_list.pkl','rb') as f:\n",
    "            dgms_list = pkl.load(f)\n",
    "        with open(outpath +f'{rsn}_{grp}_barcode1_list.pkl','rb') as f:\n",
    "            barcode1_list = pkl.load(f)\n",
    "\n",
    "        ## Persistence Landscape\n",
    "        barcode1_list_re2 = replace_infinity_by_thres(barcode1_list)\n",
    "        LS = gd.representations.Landscape(num_landscapes=1)\n",
    "        LS_fit = LS.fit_transform(barcode1_list_re2)\n",
    "        \n",
    "        L1_norm = np.linalg.norm(LS_fit, 1, axis=1)\n",
    "        L2_norm = np.linalg.norm(LS_fit, axis=1)\n",
    "        \n",
    "        with open(outpath +f'{rsn}_{grp}_L1_norm_1dim.pkl','wb') as f:\n",
    "            pkl.dump(L1_norm, f)\n",
    "        with open(outpath +f'{rsn}_{grp}_L2_norm_1dim.pkl','wb') as f:\n",
    "            pkl.dump(L2_norm, f)\n",
    "\n",
    "        ## Persistent Entropy\n",
    "        dgms_list_re2 = replace_infinity_by_thres(dgms_list)\n",
    "        PE = gd.representations.Entropy()\n",
    "        pe_dim = PE.fit_transform(dgms_list_re2)\n",
    "        \n",
    "        with open(outpath +f'{rsn}_{grp}_persistence_entropy.pkl','wb') as f:\n",
    "            pkl.dump(pe_dim, f)\n",
    "    \n",
    "        ## Store the Global data\n",
    "        Global_data = pd.DataFrame()\n",
    "        Global_data['SubID'] =  G1_ID_list if grp == Group1 else G2_ID_list\n",
    "        Global_data['L1_norm'] = L1_norm\n",
    "        Global_data['L2_norm'] = L2_norm\n",
    "        Global_data['pe_dim'] = pe_dim \n",
    "        \n",
    "        Global_data.to_csv(outpath + f'{rsn}_{grp}_L1L2PE.txt', sep = '\\t', index=False)\n",
    "        print('Done ', grp, '\\t', Global_data.shape)\n",
    "    print('Done for', rsn, '-'*80)\n",
    "    # break\n",
    "print('Done', time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e7080f-bbdd-4172-b232-5be52c0ec57c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
